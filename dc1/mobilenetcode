# Custom imports
from dc1.batch_sampler import BatchSampler
from dc1.image_dataset import ImageDataset
from dc1.net import Net
from dc1.train_test import train_model, test_model

# Torch imports
import torch
import torch.nn as nn
import torch.optim as optim
from torchsummary import summary  # type: ignore

# Other imports
import matplotlib.pyplot as plt  # type: ignore
from matplotlib.pyplot import figure
import os
import argparse
import plotext  # type: ignore
from datetime import datetime
from pathlib import Path
from typing import List 

# import numpy as np
# import tensorflow as tf
# from tensorflow.keras.applications import MobileNetV2
# from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
# from tensorflow.keras.models import Model
# from tensorflow.keras.optimizers import Adam
# from tensorflow.keras.preprocessing.image import ImageDataGenerator
import torch
import torch.nn as nn
import torchvision.models as models
import warnings
from torch.utils.data import DataLoader
import torch.optim as optim
import torchvision.transforms as transforms
from sklearn.metrics import precision_score, accuracy_score, recall_score
import numpy as np
import pandas as pd
from sklearn.metrics import classification_report
# Define image transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize images to 224x224
    transforms.ToTensor(),  # Convert images to PyTorch tensors
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images
])

train_dataset = ImageDataset(r'C:\Users\lowik\PycharmProjects\Data-Challenge-1-template\data\X_train.npy', r'C:\Users\lowik\PycharmProjects\Data-Challenge-1-template\data\Y_train.npy')

test_dataset = ImageDataset(r'C:\Users\lowik\PycharmProjects\Data-Challenge-1-template\data\X_test.npy' , r'C:\Users\lowik\PycharmProjects\Data-Challenge-1-template\data\Y_test.npy')

# Apply transformations
train_dataset.transform = transform
test_dataset.transform = transform

# Define batch size for training and testing
batch_size = 64

# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
# Suppress the warning messages
warnings.filterwarnings("ignore", category=UserWarning, module="torchvision.models._utils")

# Load the MobileNetV2 model with pretrained weights
model = models.mobilenet_v2(pretrained=True)

# Modify the first convolutional layer to accept single-channel images
# Get the original weight of the first convolutional layer
original_weight = model.features[0][0].weight.data

# Calculate the mean of the original weight along the channel dimension
mean_weight = original_weight.mean(dim=1, keepdim=True)

# Create new weight for single-channel input by repeating the mean weight
new_weight = mean_weight.repeat(1, 1, 3, 3)

# Replace the weight of the first convolutional layer with the new weight
model.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False)
model.features[0][0].weight.data = new_weight

# Modify the final fully connected layer for the new number of classes
num_classes = 6  # Assuming you have 10 classes in your dataset
model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)

# Check if GPU is available, otherwise use CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Move your model to the device
model.to(device)

# Define optimizer
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

# Define loss function (criterion)
criterion = nn.CrossEntropyLoss()

# # Move optimizer to the same device as the model
# optimizer = optimizer.to(device)

num_epochs = 10
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    train_preds = []
    train_targets = []
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        labels = labels.long()
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        _, predicted = outputs.max(1)
        train_preds.extend(predicted.cpu().numpy())
        train_targets.extend(labels.cpu().numpy())
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()
    train_loss = running_loss / len(train_loader)
    train_accuracy = 100.0 * correct / total
    train_precision = precision_score(train_targets, train_preds, average=None)
    train_recall = recall_score(train_targets, train_preds, average=None)
    class_names = ['Atelectasis', 'Effusion', 'Infiltration', 'No Finding','Nodule','Pneumothorax']
    # Validation
    model.eval()
    test_loss = 0.0
    correct = 0
    total = 0
    test_preds = []
    test_targets = []
    # Create a dictionary to map class indices to class names
    class_index_to_name = {i: class_names[i] for i in range(len(class_names))}

    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            labels = labels.long()
            outputs = model(images)
            loss = criterion(outputs, labels)
            test_loss += loss.item()
            _, predicted = outputs.max(1)
            test_preds.extend(predicted.cpu().numpy())
            test_targets.extend(labels.cpu().numpy())
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
 # Convert predicted and true labels to class names
            predicted_classes = [class_index_to_name[p.item()] for p in predicted]
            true_classes = [class_index_to_name[l.item()] for l in labels]
    test_loss /= len(test_loader)
    test_accuracy = 100.0 * correct / total
    test_precision = precision_score(test_targets, test_preds, average=None)
    test_recall = recall_score(test_targets, test_preds, average=None)
    # Generate classification report
    print("Train Classification Report:")
    print(classification_report(train_targets, train_preds, target_names=[class_index_to_name[i] for i in range(len(class_names))]))
    print("Test Classification Report:")
    print(classification_report(test_targets, test_preds, target_names=[class_index_to_name[i] for i in range(len(class_names))]))
    print(f"Epoch [{epoch + 1}/{num_epochs}], "
          f"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, "
          f"Test Loss: {test_loss:.4f}, Test Acc: {test_accuracy:.2f}%")
